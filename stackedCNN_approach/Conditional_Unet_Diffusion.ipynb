{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f20459-e463-4cf7-b1f9-e3970142dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 1: Import Necessary Libraries\n",
    "# ===============================\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vgg16\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c315b5f6-e6f7-44e1-8f57-be1defe8b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (65, 10, 1, 160, 280)\n",
      "Y_train: (65, 20, 1, 160, 280)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 2: Load and Inspect the Dataset\n",
    "# ===============================\n",
    "\n",
    "# Load dataset\n",
    "with open('./reformatedNDDs/dataset_16k_20k.pkl', 'rb') as f:\n",
    "    dataset_data = pickle.load(f)\n",
    "\n",
    "train_x, train_y = dataset_data['X_train'], dataset_data['Y_train']\n",
    "val_x, val_y = dataset_data['X_val'], dataset_data['Y_val']\n",
    "test_x, test_y = dataset_data['X_test'], dataset_data['Y_test']\n",
    "\n",
    "print(f\"X_train: {train_x.shape}\")  # Expected: (65, 10, 1, 160, 280)\n",
    "print(f\"Y_train: {train_y.shape}\")  # Expected: (65, 20, 1, 160, 280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950a980c-32be-44a7-874e-c6ffcae98dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 3: Check GPU Availability\n",
    "# ===============================\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "559611c9-9258-4835-aec6-c7727bc9361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 4: Define Data Augmentation and Dataset Classes\n",
    "# ===============================\n",
    "\n",
    "class FrameTransform:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Applies random horizontal flip and rotation to each frame.\n",
    "        \"\"\"\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=15)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, xy):\n",
    "        x, y = xy  # x and y are tensors: (frames, channels, H, W)\n",
    "\n",
    "        frames_x = []\n",
    "        frames_y = []\n",
    "        for frame_x, frame_y in zip(x, y):\n",
    "            # frame_x and frame_y are tensors: (channels, H, W)\n",
    "\n",
    "            # Apply transforms\n",
    "            frame_x = self.transform(frame_x)\n",
    "            frame_y = self.transform(frame_y)\n",
    "\n",
    "            frames_x.append(frame_x)\n",
    "            frames_y.append(frame_y)\n",
    "\n",
    "        x_transformed = torch.stack(frames_x)  # (frames, channels, H, W)\n",
    "        y_transformed = torch.stack(frames_y)\n",
    "\n",
    "        return x_transformed, y_transformed\n",
    "\n",
    "class NeuriteGrowthDataset(Dataset):\n",
    "    def __init__(self, inputs, targets, transform=None):\n",
    "        \"\"\"\n",
    "        Custom Dataset for Neurite Growth sequences.\n",
    "\n",
    "        Args:\n",
    "            inputs (np.ndarray): Healthy sequences with shape (samples, frames, channels, H, W).\n",
    "            targets (np.ndarray): Disorder-affected sequences with shape (samples, frames, channels, H, W).\n",
    "            transform (callable, optional): Transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.inputs[idx]  # Shape: (10, 1, 160, 280)\n",
    "        y = self.targets[idx]  # Shape: (20, 1, 160, 280)\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float()\n",
    "            y = torch.from_numpy(y).float()\n",
    "        else:\n",
    "            x = x.clone().detach().float()\n",
    "            y = y.clone().detach().float()\n",
    "\n",
    "        # Normalize to [-1, 1]\n",
    "        x = x * 2 - 1\n",
    "        y = y * 2 - 1\n",
    "\n",
    "        # Ensure the tensor has shape (frames, channels, H, W)\n",
    "        if x.dim() == 4 and x.shape[1] == 1:\n",
    "            pass  # Already in (frames, channels, H, W)\n",
    "        elif x.dim() == 4 and x.shape[1] > 1:\n",
    "            # Convert multi-channel to single channel by averaging if necessary\n",
    "            x = x.mean(dim=1, keepdim=True)  # (frames, 1, H, W)\n",
    "            y = y.mean(dim=1, keepdim=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Expected x and y to have 4 dimensions, got {x.dim()} and {y.dim()}\")\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            x, y = self.transform((x, y))\n",
    "\n",
    "        # Debugging: Print shapes\n",
    "        # Uncomment the following line to enable debugging prints\n",
    "        # print(f\"Dataset __getitem__ - x shape: {x.shape}, y shape: {y.shape}\")\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755a0f61-2c48-409a-bfd0-4a2290831d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 5: Define the Enhanced U-Net Architecture\n",
    "# ===============================\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.exp(-torch.arange(half_dim, dtype=torch.float32, device=device) * math.log(10000) / (half_dim - 1))\n",
    "        emb = time[:, None].float() * emb[None, :]  # (batch_size, half_dim)\n",
    "        return torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)  # (batch_size, dim)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        self.match_channels = None\n",
    "        if in_channels != out_channels or stride !=1:\n",
    "            self.match_channels = nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.match_channels is not None:\n",
    "            residual = self.match_channels(residual)\n",
    "\n",
    "        out += residual\n",
    "        return F.relu(out)\n",
    "\n",
    "class ConditionalUNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, cond_channels=1, base_channels=64):\n",
    "        super(ConditionalUNet, self).__init__()\n",
    "        \n",
    "        # Encoding path with downsampling\n",
    "        self.enc1 = ResidualBlock(in_channels + cond_channels, base_channels, stride=1)  # (batch_size,64,10,160,280)\n",
    "        self.enc2 = ResidualBlock(base_channels, base_channels * 2, stride=2)  # (batch_size,128,5,80,140)\n",
    "        self.enc3 = ResidualBlock(base_channels * 2, base_channels * 4, stride=2)  # (batch_size,256,3,40,70)\n",
    "\n",
    "        # Decoding path with upsampling\n",
    "        self.dec3 = nn.ConvTranspose3d(\n",
    "            base_channels * 4, \n",
    "            base_channels * 2, \n",
    "            kernel_size=3, \n",
    "            stride=2, \n",
    "            padding=1, \n",
    "            output_padding=0\n",
    "        )  # Upsamples from 3 to 5 frames\n",
    "        self.dec2 = nn.ConvTranspose3d(\n",
    "            base_channels * 2, \n",
    "            base_channels, \n",
    "            kernel_size=4, \n",
    "            stride=2, \n",
    "            padding=1, \n",
    "            output_padding=0\n",
    "        )  # Upsamples from 5 to 10 frames\n",
    "        self.dec1 = nn.Conv3d(base_channels, in_channels, kernel_size=3, padding=1)  # Final output\n",
    "\n",
    "        # Time embedding\n",
    "        self.time_embed = SinusoidalPosEmb(base_channels * 4)  # emb_dim=256\n",
    "\n",
    "    def forward(self, x, cond, t):\n",
    "        # Concatenate input and conditioning information along channels\n",
    "        x = torch.cat([x, cond], dim=1)  # (batch_size, 2, 10, 160, 280)\n",
    "\n",
    "        # Time embedding\n",
    "        time_emb = self.time_embed(t)  # (batch_size,256)\n",
    "        time_emb = time_emb.view(-1, time_emb.shape[1], 1, 1, 1)  # (batch_size,256,1,1,1)\n",
    "\n",
    "        # Encoding path\n",
    "        e1 = self.enc1(x)  # (batch_size,64,10,160,280)\n",
    "        e2 = self.enc2(e1)  # (batch_size,128,5,80,140)\n",
    "        e3 = self.enc3(e2)  # (batch_size,256,3,40,70)\n",
    "\n",
    "        # Add time embedding at the deepest layer\n",
    "        e3 = e3 + time_emb  # Broadcasting to (batch_size,256,3,40,70)\n",
    "\n",
    "        # Decoding path\n",
    "        d3 = F.relu(self.dec3(e3))  # (batch_size,128,5,80,140)\n",
    "\n",
    "        # Check and pad d3 to match e2's spatial dimensions\n",
    "        if d3.size(3) != e2.size(3) or d3.size(4) != e2.size(4):\n",
    "            pad_h = e2.size(3) - d3.size(3)\n",
    "            pad_w = e2.size(4) - d3.size(4)\n",
    "            # Pad (W_left, W_right, H_left, H_right, D_left, D_right)\n",
    "            # Here, pad on the right side\n",
    "            d3 = F.pad(d3, (0, pad_w, 0, pad_h, 0, 0))\n",
    "            # print(f\"Padded d3 to shape: {d3.shape}\")\n",
    "\n",
    "        # Skip connection from e2\n",
    "        if d3.shape != e2.shape:\n",
    "            print(f\"d3 shape: {d3.shape}, e2 shape: {e2.shape}\")  # Debugging\n",
    "            raise ValueError(f\"Mismatch in shape during skip connection: d3={d3.shape}, e2={e2.shape}\")\n",
    "        d3 = d3 + e2  # (batch_size,128,5,80,140)\n",
    "\n",
    "        d2 = F.relu(self.dec2(d3))  # (batch_size,64,10,160,280)\n",
    "\n",
    "        # Skip connection from e1\n",
    "        if d2.shape != e1.shape:\n",
    "            print(f\"d2 shape: {d2.shape}, e1 shape: {e1.shape}\")  # Debugging\n",
    "            raise ValueError(f\"Mismatch in shape during skip connection: d2={d2.shape}, e1={e1.shape}\")\n",
    "        d2 = d2 + e1  # (batch_size,64,10,160,280)\n",
    "\n",
    "        out = self.dec1(d2)  # (batch_size,1,10,160,280)\n",
    "\n",
    "        return out  # (batch_size,1,10,160,280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea2ba29-1368-463a-8373-e250c6ee7610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 6: Define the Diffusion Process\n",
    "# ===============================\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    \"\"\"\n",
    "    Generates a cosine beta schedule.\n",
    "\n",
    "    Args:\n",
    "        timesteps (int): Number of diffusion steps.\n",
    "        s (float, optional): Small constant to prevent division by zero. Defaults to 0.008.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Beta schedule.\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    betas = torch.clip(betas, 0, 0.999)\n",
    "    return betas\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, timesteps=1000, device='cuda'):\n",
    "        \"\"\"\n",
    "        Diffusion process for adding and removing noise.\n",
    "\n",
    "        Args:\n",
    "            timesteps (int, optional): Number of diffusion steps. Defaults to 1000.\n",
    "            device (str, optional): Device to run on. Defaults to 'cuda'.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.timesteps = timesteps\n",
    "        self.betas = cosine_beta_schedule(timesteps).to(device)\n",
    "\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod).to(device)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - self.alphas_cumprod).to(device)\n",
    "\n",
    "    def add_noise(self, x0, t):\n",
    "        \"\"\"\n",
    "        Adds noise to the data at timestep t.\n",
    "\n",
    "        Args:\n",
    "            x0 (torch.Tensor): Original data.\n",
    "            t (torch.Tensor): Timestep indices.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Noisy data and the noise added.\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(x0).to(self.device)\n",
    "        sqrt_alphas_cumprod_t = self.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1, 1)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1, 1)\n",
    "        xt = sqrt_alphas_cumprod_t * x0 + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "        return xt, noise  # Both xt and noise have the same shape as x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8634ef8-2def-4b66-8f6b-acb67bbcddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/ussqww/.conda/envs/OpenSTL/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/jet/home/ussqww/.conda/envs/OpenSTL/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 7: Define Loss Functions\n",
    "# ===============================\n",
    "\n",
    "# Use a pre-trained VGG model for perceptual loss\n",
    "vgg = vgg16(pretrained=True).features[:16].to(device).eval()\n",
    "\n",
    "def perceptual_loss(pred, target):\n",
    "    \"\"\"\n",
    "    Computes perceptual loss using VGG features.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): Predicted noise.\n",
    "        target (torch.Tensor): Actual noise.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Perceptual loss.\n",
    "    \"\"\"\n",
    "    # Convert to 3 channels if necessary\n",
    "    if pred.shape[1] == 1:\n",
    "        pred_rgb = pred.repeat(1, 3, 1, 1, 1)\n",
    "        target_rgb = target.repeat(1, 3, 1, 1, 1)\n",
    "    else:\n",
    "        pred_rgb = pred\n",
    "        target_rgb = target\n",
    "\n",
    "    # Normalize for VGG\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=pred.device).view(1, 3, 1, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225], device=pred.device).view(1, 3, 1, 1, 1)\n",
    "\n",
    "    pred_norm = (pred_rgb + 1) / 2  # [0,1]\n",
    "    pred_norm = (pred_norm - mean) / std\n",
    "\n",
    "    target_norm = (target_rgb + 1) / 2\n",
    "    target_norm = (target_norm - mean) / std\n",
    "\n",
    "    # Reshape to (batch_size*frames, 3, H, W) to pass through VGG\n",
    "    pred_norm = pred_norm.view(-1, 3, pred_norm.shape[3], pred_norm.shape[4])\n",
    "    target_norm = target_norm.view(-1, 3, target_norm.shape[3], target_norm.shape[4])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        target_features = vgg(target_norm)\n",
    "\n",
    "    pred_features = vgg(pred_norm)\n",
    "    return F.mse_loss(pred_features, target_features)\n",
    "\n",
    "l1_loss = nn.L1Loss()\n",
    "\n",
    "def combined_loss(pred, target, alpha=0.7):\n",
    "    \"\"\"\n",
    "    Combines L1 loss and perceptual loss.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): Predicted noise.\n",
    "        target (torch.Tensor): Actual noise.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Combined loss.\n",
    "    \"\"\"\n",
    "    l1 = l1_loss(pred, target)\n",
    "    perceptual = perceptual_loss(pred, target)\n",
    "    return alpha * l1 + (1 - alpha) * perceptual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267523fa-f03e-4a26-94cf-6aeea34384a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 8: Initialize Datasets and DataLoaders with Augmentation\n",
    "# ===============================\n",
    "\n",
    "batch_size = 16  # Adjust based on your GPU memory\n",
    "\n",
    "# Create Dataset instances with data augmentation for training\n",
    "train_dataset = NeuriteGrowthDataset(train_x, train_y, transform=FrameTransform())\n",
    "val_dataset = NeuriteGrowthDataset(val_x, val_y)  # No augmentation for validation\n",
    "test_dataset = NeuriteGrowthDataset(test_x, test_y)  # No augmentation for testing\n",
    "\n",
    "# Create DataLoaders with optimizations\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=4, \n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=4, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=4, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864935d9-438d-4db9-9df5-3957aeb39f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 9: Initialize the Model, Optimizer, Diffusion Process, and Scaler\n",
    "# ===============================\n",
    "\n",
    "model = ConditionalUNet(in_channels=1, cond_channels=1, base_channels=64).to(device)\n",
    "\n",
    "# Wrap the model with DataParallel to use multiple GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5, verbose=True)\n",
    "diffusion = Diffusion(timesteps=1000, device=device)\n",
    "scaler = GradScaler()  # For mixed precision training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac7baa1-05ce-4bef-a338-ca0bcb62cef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 7.677693\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_1.pth with a loss of 7.677693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200], Loss: 7.081687\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_2.pth with a loss of 7.081687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200: 100%|██████████| 5/5 [00:03<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200], Loss: 6.519331\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_3.pth with a loss of 6.519331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200], Loss: 5.908103\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_4.pth with a loss of 5.908103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Loss: 5.910053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200], Loss: 5.173400\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_6.pth with a loss of 5.173400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200], Loss: 4.995109\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_7.pth with a loss of 4.995109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200], Loss: 4.847290\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_8.pth with a loss of 4.847290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200], Loss: 4.878041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 4.574693\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_10.pth with a loss of 4.574693\n",
      "Sun Sep 29 15:42:26 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   52C    P0              74W / 300W |  21091MiB / 32768MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     46174      C   ...qww/.conda/envs/OpenSTL/bin/python3    21086MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200], Loss: 4.663915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200], Loss: 4.505817\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_12.pth with a loss of 4.505817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200], Loss: 3.937246\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_13.pth with a loss of 3.937246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200: 100%|██████████| 5/5 [00:03<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/200], Loss: 4.066898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/200], Loss: 4.025561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/200], Loss: 4.426147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200: 100%|██████████| 5/5 [00:03<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/200], Loss: 3.789548\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_17.pth with a loss of 3.789548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/200], Loss: 3.706849\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_18.pth with a loss of 3.706849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/200], Loss: 4.316695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200], Loss: 3.555432\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_20.pth with a loss of 3.555432\n",
      "Sun Sep 29 15:43:00 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   54C    P0              75W / 300W |  21091MiB / 32768MiB |     28%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     46174      C   ...qww/.conda/envs/OpenSTL/bin/python3    21086MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/200], Loss: 4.161513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/200], Loss: 3.597090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/200], Loss: 3.944292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200], Loss: 4.159632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/200], Loss: 3.430937\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_25.pth with a loss of 3.430937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/200], Loss: 3.603115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/200], Loss: 3.509348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/200], Loss: 3.427119\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_28.pth with a loss of 3.427119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/200], Loss: 3.314096\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_29.pth with a loss of 3.314096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200], Loss: 3.485348\n",
      "Sun Sep 29 15:43:34 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   55C    P0              82W / 300W |  21091MiB / 32768MiB |     67%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     46174      C   ...qww/.conda/envs/OpenSTL/bin/python3    21086MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/200], Loss: 3.318998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/200], Loss: 3.975500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/200], Loss: 3.898452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/200], Loss: 2.984409\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_34.pth with a loss of 2.984409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/200], Loss: 2.834085\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_35.pth with a loss of 2.834085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/200], Loss: 2.562435\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_36.pth with a loss of 2.562435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/200], Loss: 3.127327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/200], Loss: 2.762575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/200], Loss: 2.869269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/200], Loss: 2.208860\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_40.pth with a loss of 2.208860\n",
      "Sun Sep 29 15:44:08 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   54C    P0              74W / 300W |  21091MiB / 32768MiB |     39%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     46174      C   ...qww/.conda/envs/OpenSTL/bin/python3    21086MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/200], Loss: 2.289571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/200], Loss: 2.257437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/200: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/200], Loss: 1.959504\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_43.pth with a loss of 1.959504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/200], Loss: 2.151804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/200], Loss: 2.411413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/200], Loss: 2.095071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/200], Loss: 2.134788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/200: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/200], Loss: 2.018716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/200], Loss: 1.851973\n",
      "Checkpoint saved at ./checkpoints/conditional_unet_best_epoch_49.pth with a loss of 1.851973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/200: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/200], Loss: 3.050195\n",
      "Sun Sep 29 15:44:42 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   55C    P0              82W / 300W |  21091MiB / 32768MiB |     67%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     46174      C   ...qww/.conda/envs/OpenSTL/bin/python3    21086MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/200], Loss: 2.058796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/200], Loss: 2.380569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/200: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/200], Loss: 1.867178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/200: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/200], Loss: 2.436938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/200:  40%|████      | 2/5 [00:01<00:02,  1.08it/s]"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 10: Define the Training Loop with Mixed Precision and Perceptual Loss\n",
    "# ===============================\n",
    "        \n",
    "num_epochs = 200  # Adjust as needed\n",
    "\n",
    "# Optional: Create a directory to save checkpoints\n",
    "checkpoint_dir = './checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Initialize the best loss variable\n",
    "best_loss = float('inf')  # Set to infinity so the first loss is always lower\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for healthy_seq, disorder_seq in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        healthy_seq = healthy_seq.to(device)  # Shape: (batch_size, 10, 1, 160, 280)\n",
    "        disorder_seq = disorder_seq.to(device)  # Shape: (batch_size, 20, 1, 160, 280)\n",
    "\n",
    "        # Permute to (batch_size, channels, frames, height, width)\n",
    "        healthy_seq = healthy_seq.permute(0, 2, 1, 3, 4)  # Shape: (batch_size, 1, 10, 160, 280)\n",
    "        disorder_seq = disorder_seq.permute(0, 2, 1, 3, 4)  # Shape: (batch_size, 1, 20, 160, 280)\n",
    "\n",
    "        # Debugging: Print shapes after permutation\n",
    "        # Uncomment the following line to enable debugging prints\n",
    "        # print(f\"After permute - healthy_seq: {healthy_seq.shape}, disorder_seq: {disorder_seq.shape}\")\n",
    "\n",
    "        # Upsample healthy_seq to match frames dimension of disorder_seq if necessary\n",
    "        if healthy_seq.size(2) != disorder_seq.size(2):\n",
    "            healthy_seq = F.interpolate(\n",
    "                healthy_seq,\n",
    "                size=(disorder_seq.size(2), disorder_seq.size(3), disorder_seq.size(4)),\n",
    "                mode='trilinear',\n",
    "                align_corners=False\n",
    "            )  # Shape: (batch_size, 1, 20, 160, 280)\n",
    "            # Debugging: Print shapes after interpolation\n",
    "            # Uncomment the following line to enable debugging prints\n",
    "            # print(f\"After interpolation - healthy_seq: {healthy_seq.shape}\")\n",
    "\n",
    "        batch_size_current = disorder_seq.size(0)\n",
    "        t = torch.randint(0, diffusion.timesteps, (batch_size_current,), device=device).long()\n",
    "\n",
    "        # Add noise to disorder-affected sequence\n",
    "        x_t, noise = diffusion.add_noise(disorder_seq, t)  # Both x_t and noise: (batch_size, 1, 20, 160, 280)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            # Predict the noise given the noisy input and healthy sequence\n",
    "            predicted_noise = model(x_t, healthy_seq, t)  # Shape: (batch_size, 1, 10, 160, 280)\n",
    "            \n",
    "            # Debugging: Check if predicted_noise is None\n",
    "            if predicted_noise is None:\n",
    "                raise ValueError(\"Model returned None for predicted_noise\")\n",
    "            if noise is None:\n",
    "                raise ValueError(\"Noise tensor is None\")\n",
    "            # print(f\"predicted_noise shape: {predicted_noise.shape}\")\n",
    "            # print(f\"noise shape: {noise.shape}\")\n",
    "\n",
    "            # Compute combined loss (L1 + perceptual loss)\n",
    "            loss = combined_loss(predicted_noise, noise)  # Scalar\n",
    "\n",
    "        # Scale the loss and backpropagate\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Optional: Gradient Clipping to prevent exploding gradients\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}\")\n",
    "        \n",
    "    # Use the scheduler to adjust the learning rate based on the current loss\n",
    "    scheduler.step(avg_loss)  # Pass the average loss (or validation loss) to the scheduler\n",
    "\n",
    "    # Optional: Save model checkpoint if the current loss is lower than the best loss\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss  # Update the best loss\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'conditional_unet_best_epoch_{epoch+1}.pth')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path} with a loss of {avg_loss:.6f}\")\n",
    "\n",
    "    # Optional: Save model checkpoints periodically\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        subprocess.run(['nvidia-smi'])\n",
    "        # checkpoint_path = os.path.join(checkpoint_dir, f'conditional_unet_epoch_{epoch+1}.pth')\n",
    "        # torch.save(model.state_dict(), checkpoint_path)\n",
    "        # print(f\"Checkpoint saved at {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709606f-c516-4559-b664-6fe7c75ed0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 11: Define the Sampling and Visualization Functions\n",
    "# ===============================\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model, diffusion, conditioning_seq, num_frames=20):\n",
    "    \"\"\"\n",
    "    Generates samples using the trained diffusion model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained diffusion model.\n",
    "        diffusion (Diffusion): Diffusion process instance.\n",
    "        conditioning_seq (torch.Tensor): Conditioning sequence (batch_size, channels, frames, H, W).\n",
    "        num_frames (int, optional): Number of frames in the generated sequence. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Generated sequence.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = diffusion.device\n",
    "    batch_size = conditioning_seq.size(0)\n",
    "\n",
    "    # Upsample conditioning_seq to match num_frames if necessary\n",
    "    if conditioning_seq.size(2) != num_frames:\n",
    "        conditioning_seq = F.interpolate(\n",
    "            conditioning_seq,\n",
    "            size=(num_frames, conditioning_seq.size(3), conditioning_seq.size(4)),\n",
    "            mode='trilinear',\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "    # Initialize the noisy image\n",
    "    shape = (batch_size, 1, num_frames, conditioning_seq.size(-2), conditioning_seq.size(-1))\n",
    "    img = torch.randn(shape).to(device)\n",
    "\n",
    "    for i in tqdm(reversed(range(diffusion.timesteps)), desc=\"Sampling\"):\n",
    "        t = torch.full((batch_size,), i, device=device, dtype=torch.long)\n",
    "\n",
    "        # Predict the noise\n",
    "        predicted_noise = model(img, conditioning_seq, t)  # Shape: (batch_size,1,20,160,280)\n",
    "\n",
    "        # Update image\n",
    "        alpha = diffusion.alphas[t].view(-1, 1, 1, 1, 1)\n",
    "        beta = diffusion.betas[t].view(-1, 1, 1, 1, 1)\n",
    "        alpha_hat = diffusion.alphas_cumprod[t].view(-1, 1, 1, 1, 1)\n",
    "        if i > 0:\n",
    "            noise = torch.randn_like(img)\n",
    "        else:\n",
    "            noise = torch.zeros_like(img)\n",
    "        img = (1 / torch.sqrt(alpha)) * (img - ((1 - alpha) / torch.sqrt(1 - alpha_hat)) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "\n",
    "    return img  # Shape: (batch_size,1,20,160,280)\n",
    "\n",
    "def show_sequence(sequence, nrows=1, ncols=20):\n",
    "    \"\"\"\n",
    "    Displays a sequence of frames.\n",
    "\n",
    "    Args:\n",
    "        sequence (torch.Tensor): Sequence to display (batch_size, channels, frames, H, W).\n",
    "        nrows (int, optional): Number of rows in the plot grid. Defaults to 1.\n",
    "        ncols (int, optional): Number of columns (frames) to display. Defaults to 20.\n",
    "    \"\"\"\n",
    "    sequence = sequence.cpu().numpy()\n",
    "    batch_size, channels, frames, height, width = sequence.shape\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 2, nrows * 2))\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            if nrows == 1:\n",
    "                ax = axes[j]\n",
    "            else:\n",
    "                ax = axes[i, j]\n",
    "            if j < frames:\n",
    "                img = sequence[i, 0, j]\n",
    "                ax.imshow(img, cmap='gray')\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb12151f-8460-47a5-a387-5995ced1705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 12: Generate and Visualize Samples\n",
    "# ===============================\n",
    "\n",
    "# Get a batch of healthy sequences from the test set\n",
    "test_iter = iter(test_loader)\n",
    "healthy_seq, _ = next(test_iter)\n",
    "healthy_seq = healthy_seq.to(device)  # Shape: (batch_size, 10, 1, 160, 280)\n",
    "\n",
    "# Permute to (batch_size, channels, frames, height, width)\n",
    "healthy_seq = healthy_seq.permute(0, 2, 1, 3, 4)  # Shape: (batch_size, 1, 10, 160, 280)\n",
    "\n",
    "# Generate samples\n",
    "generated_seq = sample(model, diffusion, healthy_seq, num_frames=10)  # Shape: (batch_size,1,20,160,280)\n",
    "\n",
    "# Convert generated_seq from [-1, 1] to [0, 1] for visualization\n",
    "generated_seq = (generated_seq + 1) / 2\n",
    "\n",
    "# Optionally, display the corresponding healthy sequence\n",
    "healthy_seq_display = (healthy_seq + 1) / 2  # Convert back to [0, 1]\n",
    "show_sequence(healthy_seq_display, nrows=1, ncols=10)\n",
    "\n",
    "# Visualize generated sequence\n",
    "show_sequence(generated_seq, nrows=1, ncols=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a36ba-dc49-43b3-90b5-c925649db01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===============================\n",
    "# Step 13: Save the Trained Model\n",
    "# ===============================\n",
    "\n",
    "torch.save(model.state_dict(), 'conditional_unet.pth')\n",
    "# To load the model later:\n",
    "# model.load_state_dict(torch.load('conditional_unet.pth'))\n",
    "\n",
    "# %%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSTL",
   "language": "python",
   "name": "openstl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
