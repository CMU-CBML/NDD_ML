{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_seq_length = 10\n",
    "aft_seq_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def sample_frames(video_path, num_frames=20):\n",
    "    # read the video\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # uniformly sample frames from the video\n",
    "    frame_idxs = np.linspace(0, total_frames-1, num_frames, dtype=int)\n",
    "    frames = []\n",
    "    for idx in frame_idxs:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        _, frame = video.read()\n",
    "        # frame = cv2.resize(frame, (height, width))\n",
    "        frames.append(frame)\n",
    "    video.release()\n",
    "    return np.stack(frames)\n",
    "\n",
    "def process_folder(folder_path, pre_slen=10, aft_slen=10, suffix='.avi'):\n",
    "    # get all the videos in this folder\n",
    "    videos = []\n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        video_path = os.path.join(folder_path, file)\n",
    "        if os.path.isfile(video_path) and file.endswith(suffix):\n",
    "            video = sample_frames(video_path, pre_slen + aft_slen)\n",
    "            videos.append(video)\n",
    "    # stack video frames from each folder\n",
    "    data = np.stack(videos).transpose(0, 1, 4, 2, 3)\n",
    "\n",
    "    # if the data is in [0, 255], rescale it into [0, 1]\n",
    "    if data.max() > 1.0:\n",
    "        data = data.astype(np.float32) / 255.0\n",
    "\n",
    "    return data[:, :pre_slen], data[:, pre_slen:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset and visualize an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (93, 10, 1, 160, 280)\n",
      "Y_train: (93, 20, 1, 160, 280)\n",
      "X_test: (21, 10, 1, 160, 280)\n",
      "Y_test: (21, 20, 1, 160, 280)\n",
      "X_val: (20, 10, 1, 160, 280)\n",
      "Y_val: (20, 20, 1, 160, 280)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# load the dataset\n",
    "# with open('dataset.pkl', 'rb') as f:\n",
    "# with open('./reformatedNDDs/dataset_16k_20k_all.pkl', 'rb') as f:\n",
    "# with open('./reformatedNDDs/dataset_16k_20k_Dc.pkl', 'rb') as f:\n",
    "with open('./reformatedNDDs/dataset_16k_20k_all_10152024.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "train_x, train_y = dataset['X_train'], dataset['Y_train']\n",
    "print(f\"X_train: {dataset['X_train'].shape}\")\n",
    "print(f\"Y_train: {dataset['Y_train'].shape}\")\n",
    "print(f\"X_test: {dataset['X_test'].shape}\")\n",
    "print(f\"Y_test: {dataset['Y_test'].shape}\")\n",
    "print(f\"X_val: {dataset['X_val'].shape}\")\n",
    "print(f\"Y_val: {dataset['Y_val'].shape}\")\n",
    "\n",
    "# the shape is B x T x C x H x W\n",
    "# B: the number of samples\n",
    "# T: the number of frames in each sample\n",
    "# C, H, W: the channel, height, width of each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'openstl' from '/ocean/projects/eng170006p/ussqww/OpenSTL-OpenSTL-Lightning/openstl/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openstl\n",
    "import importlib\n",
    "importlib.reload(openstl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openstl.utils import show_video_line\n",
    "\n",
    "# # show the given frames from an example\n",
    "# example_idx = np.random.randint(0, len(train_x))\n",
    "# show_video_line(train_x[example_idx], ncols=pre_seq_length, vmax=0.6, cbar=False, out_path=None, format='png', use_rgb=False)\n",
    "# # show the future frames from an example\n",
    "# show_video_line(train_y[example_idx], ncols=aft_seq_length, vmax=0.6, cbar=False, out_path=None, format='png', use_rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y, normalize=False, data_name='custom'):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.data_name = data_name\n",
    "\n",
    "        if normalize:\n",
    "            # get the mean/std values along the channel dimension\n",
    "            mean = data.mean(axis=(0, 1, 2, 3)).reshape(1, 1, -1, 1, 1)\n",
    "            std = data.std(axis=(0, 1, 2, 3)).reshape(1, 1, -1, 1, 1)\n",
    "            data = (data - mean) / std\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.tensor(self.X[index]).float()\n",
    "        labels = torch.tensor(self.Y[index]).float()\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test = dataset['X_train'], dataset[\n",
    "    'X_val'], dataset['X_test'], dataset['Y_train'], dataset['Y_val'], dataset['Y_test']\n",
    "\n",
    "train_set = CustomDataset(X=X_train, Y=Y_train)\n",
    "val_set = CustomDataset(X=X_val, Y=Y_val)\n",
    "test_set = CustomDataset(X=X_test, Y=Y_test)\n",
    "# Concatenate train, val, and test sets for the final test set\n",
    "# X_all = np.concatenate([X_train, X_val, X_test], axis=0)\n",
    "# Y_all = np.concatenate([Y_train, Y_val, Y_test], axis=0)\n",
    "# test_set = CustomDataset(X=X_all, Y=Y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "dataloader_val = torch.utils.data.DataLoader(\n",
    "    val_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_training_config = {\n",
    "    'pre_seq_length': pre_seq_length,\n",
    "    'aft_seq_length': aft_seq_length,\n",
    "    'total_length': pre_seq_length + aft_seq_length,\n",
    "    'batch_size': batch_size,\n",
    "    'val_batch_size': batch_size,\n",
    "    'epoch': 100,\n",
    "    'lr': 0.001,   \n",
    "    'metrics': ['mse', 'mae', 'lpips', 'ssim'],\n",
    "    # 'metrics': ['mse', 'mae', 'perceptual'],\n",
    "\n",
    "    'ex_name': 'custom_exp',\n",
    "    'dataname': 'custom',\n",
    "    'in_shape': [10, 1, 32, 32],\n",
    "}\n",
    "\n",
    "custom_model_config = {\n",
    "    # For MetaVP models, the most important hyperparameters are: \n",
    "    # N_S, N_T, hid_S, hid_T, model_type\n",
    "    'method': 'SimVP',\n",
    "    # Users can either using a config file or directly set these hyperparameters \n",
    "    # 'config_file': 'configs/custom/example_model.py',\n",
    "    \n",
    "    # Here, we directly set these parameters\n",
    "    'model_type': 'gSTA',\n",
    "    'N_S': 4,\n",
    "    'N_T': 8,\n",
    "    'hid_S': 64,\n",
    "    'hid_T': 256\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the experiment\n",
    "\n",
    "We retrieve the default hyperparameters by utilizing `create_parser` and update those hyperparameters that are defined in `custom_training_config` and `custom_model_config`. \n",
    "\n",
    "By utilizing `BaseExperiment`, we ensure that everything is prepared, including dataloader setup and model initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openstl.api import BaseExperiment\n",
    "from openstl.utils import create_parser, default_parser\n",
    "\n",
    "args = create_parser().parse_args([])\n",
    "config = args.__dict__\n",
    "\n",
    "# update the training config\n",
    "config.update(custom_training_config)\n",
    "# update the model config\n",
    "config.update(custom_model_config)\n",
    "# fulfill with default values\n",
    "default_values = default_parser()\n",
    "for attribute in default_values.keys():\n",
    "    if config[attribute] is None:\n",
    "        config[attribute] = default_values[attribute]\n",
    "        \n",
    "exp = BaseExperiment(args, dataloaders=(dataloader_train, dataloader_val, dataloader_test), strategy='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "print('>'*35 + ' training ' + '<'*35)\n",
    "exp.train()\n",
    "\n",
    "print('>'*35 + ' testing  ' + '<'*35)\n",
    "exp.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openstl.utils import show_video_line\n",
    "\n",
    "# Load the inputs, predictions, and true values\n",
    "inputs = np.load('./work_dirs/custom_exp/saved/inputs.npy')\n",
    "preds = np.load('./work_dirs/custom_exp/saved/preds.npy')\n",
    "trues = np.load('./work_dirs/custom_exp/saved/trues.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random index for the example\n",
    "example_idx = np.random.randint(0, len(inputs))\n",
    "\n",
    "# Show the frames for the input, prediction, and ground truth\n",
    "show_video_line(inputs[example_idx], ncols=10, vmax=0.6, cbar=False, out_path=None, format='png', use_rgb=False)\n",
    "show_video_line(preds[example_idx], ncols=20, vmax=0.6, cbar=False, out_path=None, format='png', use_rgb=False)\n",
    "show_video_line(trues[example_idx], ncols=20, vmax=0.6, cbar=False, out_path=None, format='png', use_rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ComputeTestError(prediction, target):\n",
    "    num_pixels = np.prod(target.shape)\n",
    "    squared_error = np.sum((target - prediction) ** 2) / num_pixels\n",
    "    phi_gt_max = np.max(target)\n",
    "    phi_gt_min = np.min(target)\n",
    "    mre = np.sqrt(squared_error) / (phi_gt_max - phi_gt_min) * 100\n",
    "    \n",
    "    return mre\n",
    "\n",
    "def TestErrorPlot(pred, true, figsize=(10, 6), dpi=200, out_path=\"./statistics_testdata.png\"):\n",
    "    \"\"\"Plot the test error for the given predictions and true data, save as PNG.\"\"\"\n",
    "    error_List = []\n",
    "    testID_List = []\n",
    "    count = 1\n",
    "\n",
    "    # Get the number of cases and number of comparisons from pred.shape\n",
    "    num_cases = pred.shape[0]\n",
    "    num_comparisons = pred.shape[1]\n",
    "\n",
    "    # Loop through each case in the prediction and true arrays\n",
    "    for i in range(num_cases):\n",
    "        # Use a qualitative colormap for contrasting colors (e.g., tab20 colormap)\n",
    "        color = plt.cm.tab20(i % 20)  # Ensures up to 20 distinct colors\n",
    "        \n",
    "        # For each case, we calculate the error for all comparisons (inferred from pred.shape[1])\n",
    "        for j in range(num_comparisons):\n",
    "            # Compute test error for each comparison\n",
    "            tmp_error = ComputeTestError(pred[i, j], true[i, j])\n",
    "            error_List.append(tmp_error)\n",
    "            testID_List.append(count)\n",
    "\n",
    "            # Vary transparency (alpha) based on comparison position in the case\n",
    "            alpha_value = (j + 1) / num_comparisons  # Later points are more transparent\n",
    "            plt.plot(count, tmp_error, 'o', color=color, markersize=4, alpha=alpha_value)\n",
    "            count += 1\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    testID_List = np.asarray(testID_List)\n",
    "    error_List = np.asarray(error_List)\n",
    "    avg_error = np.average(error_List)\n",
    "    \n",
    "    # Plot the average error line across all cases\n",
    "    plt.axhline(avg_error, color='red', linestyle='--', linewidth=2, label=f'Average Error: {avg_error:.4f}%')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Samples (color = case, darker = later prediction)', fontsize=12)\n",
    "    plt.ylabel('Mean Relative Error (%)', fontsize=12)\n",
    "    plt.title('Accuracy Statistics Plot for Test Dataset', fontsize=14)\n",
    "\n",
    "    # Add gridlines for better readability\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Add a legend for the average error\n",
    "    plt.legend(loc='upper right', fontsize=8)  # Smaller legend font size\n",
    "    \n",
    "    # Save the figure with the specified size and resolution\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=dpi, format='png')\n",
    "\n",
    "    # Display the average error in the terminal\n",
    "    print(f'Average Error: {avg_error:.4f}%')\n",
    "    print(f'Max error index: {np.argmax(error_List)}')\n",
    "\n",
    "# Call the TestErrorPlot function\n",
    "TestErrorPlot(preds, trues, figsize=(20, 8), dpi=300, out_path=\"./test_error_plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "def show_video_gif_multiple_withError(prev, true, pred, vmax=1.0, vmin=0.0, cmap='jet', norm=None, out_path=None, use_rgb=False):\n",
    "    \"\"\"Generate gif with a video sequence and plot absolute error along with mean relative error using provided MRE formula.\"\"\"\n",
    "    \n",
    "    def swap_axes(x):\n",
    "        if len(x.shape) > 3:\n",
    "            return x.swapaxes(1, 2).swapaxes(2, 3)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    prev, true, pred = map(swap_axes, [prev, true, pred])\n",
    "    prev_frames = prev.shape[0]\n",
    "    frames = prev_frames + true.shape[0]\n",
    "    images = []\n",
    "    \n",
    "    for i in range(frames):\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 9))  # Larger figsize for higher resolution\n",
    "        for t, ax in enumerate(axes):\n",
    "            if t == 0:\n",
    "                plt.text(0.3, 1.05, 'Ground Truth', fontsize=15, color='green', transform=ax.transAxes)\n",
    "                if i < prev_frames:\n",
    "                    frame = prev[i]\n",
    "                else:\n",
    "                    frame = true[i - prev_frames]\n",
    "                im = ax.imshow(frame, cmap=cmap, norm=norm, vmin=vmin, vmax=vmax)\n",
    "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04, aspect=10)\n",
    "                cbar.ax.tick_params(labelsize=8)\n",
    "                cbar.set_label('Pixel Value', fontsize=10)\n",
    "                \n",
    "            elif t == 1:\n",
    "                plt.text(0.2, 1.05, 'Predicted Frames', fontsize=15, color='red', transform=ax.transAxes)\n",
    "                if i < prev_frames:\n",
    "                    frame = prev[i]\n",
    "                else:\n",
    "                    frame = pred[i - prev_frames]\n",
    "                frame = frame\n",
    "                im = ax.imshow(frame, cmap=cmap, norm=norm, vmin=vmin, vmax=vmax)\n",
    "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04, aspect=10)\n",
    "                cbar.ax.tick_params(labelsize=8)\n",
    "                cbar.set_label('Pixel Value', fontsize=10)\n",
    "                \n",
    "            elif t == 2:\n",
    "                plt.text(0.2, 1.05, 'Absolute Error', fontsize=15, color='blue', transform=ax.transAxes)\n",
    "                if i < prev_frames:\n",
    "                    # Plot prev - prev (which should result in all zeros)\n",
    "                    abs_error = np.zeros_like(prev[i])\n",
    "                    mre = 0.0  # No error, as we are comparing the same frames\n",
    "                else:\n",
    "                    # Plot absolute error for the remaining frames\n",
    "                    abs_error = np.abs(true[i - prev_frames] - pred[i - prev_frames])\n",
    "                    \n",
    "                    # Calculate MRE using the provided formula\n",
    "                    phi_gt = true[i - prev_frames]\n",
    "                    phi_pred = pred[i - prev_frames]\n",
    "                    num_pixels = np.prod(phi_gt.shape)\n",
    "                    squared_error = np.sum((phi_gt - phi_pred) ** 2) / num_pixels\n",
    "                    phi_gt_max = np.max(phi_gt)\n",
    "                    phi_gt_min = np.min(phi_gt)\n",
    "                    mre = np.sqrt(squared_error) / (phi_gt_max - phi_gt_min) * 100\n",
    "\n",
    "                im = ax.imshow(abs_error, cmap=cmap, norm=norm, vmin=vmin, vmax=vmax)\n",
    "                cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04, aspect=10)\n",
    "                cbar.ax.tick_params(labelsize=8)\n",
    "                cbar.set_label('Absolute Error', fontsize=10)\n",
    "                \n",
    "                # Use ax.text() to manually place MRE below the third subplot\n",
    "                ax.text(0.5, -0.1, f'Mean Relative Error: {mre:.4f}%', \n",
    "                        fontsize=12, color='blue', ha='center', transform=ax.transAxes)\n",
    "\n",
    "            ax.axis('off')\n",
    "        \n",
    "        # Save the frame to the temporary image and append to images list for GIF creation\n",
    "        plt.savefig(f'./tmp_frame_{i}.png', bbox_inches='tight', format='png', dpi=300)  # Higher DPI\n",
    "        images.append(imageio.imread(f'./tmp_frame_{i}.png'))\n",
    "        plt.close()\n",
    "\n",
    "    # Remove temporary files after GIF creation\n",
    "    if out_path is not None:\n",
    "        if not out_path.endswith('gif'):\n",
    "            out_path = out_path + '.gif'\n",
    "        \n",
    "        # Create GIF using the frames and set it to loop infinitely (loop=0)\n",
    "        imageio.mimsave(out_path, images, duration=0.1, loop=0)  # loop=0 for infinite looping GIF\n",
    "\n",
    "    # Optionally, clean up the temporary files after GIF creation\n",
    "    for i in range(frames):\n",
    "        os.remove(f'./tmp_frame_{i}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the function for generating GIFs\n",
    "# from openstl.utils import show_video_gif_multiple\n",
    "\n",
    "for i in range(len(inputs)):\n",
    "    example_idx = i\n",
    "\n",
    "    # Modify the output filename to include the random index\n",
    "    output_gif_filename = f'./prediction_gif/example_{example_idx}.gif'\n",
    "    # show_video_gif_multiple(inputs[example_idx], trues[example_idx], preds[example_idx], out_path=output_gif_filename)\n",
    "    show_video_gif_multiple_withError(inputs[example_idx], trues[example_idx], preds[example_idx], out_path=output_gif_filename)\n",
    "\n",
    "    print(f\"GIF saved as {output_gif_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "def show_video_gif_multiple_withError(prev, true, pred, vmax=1.0, vmin=0.0, cmap='jet', norm=None, out_path=None, use_rgb=False):\n",
    "    \"\"\"Generate a 3-row figure with ground truth, prediction, and error, handling initial 10 frames in prev and subsequent 20 frames in true/pred.\"\"\"\n",
    "    \n",
    "    def swap_axes(x):\n",
    "        if len(x.shape) > 3:\n",
    "            return x.swapaxes(1, 2).swapaxes(2, 3)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    prev, true, pred = map(swap_axes, [prev, true, pred])\n",
    "    prev_frames = prev.shape[0]  # prev contains the first 10 frames\n",
    "    true_frames = true.shape[0]  # true contains the next 20 frames\n",
    "    pred_frames = pred.shape[0]  # pred contains the next 20 frames\n",
    "\n",
    "    # Sample ground truth: 3 frames from 0-9 in prev, 5 frames from 10-29 in true\n",
    "    sampled_gt_indices_prev = [0, 5, 9]  # Frames 0, 5, 9 from prev\n",
    "    sampled_gt_indices_true = list(np.linspace(10, 29, 5, dtype=int))  # 5 frames from true (10-29)\n",
    "    \n",
    "    # Sample prediction: 5 frames from pred (10-29)\n",
    "    sampled_pred_indices = list(np.linspace(0, pred_frames - 1, 5, dtype=int))  # Sampling within pred frames (0 to 19 in pred)\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists('prediction_gif'):\n",
    "        os.makedirs('prediction_gif')\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=3, ncols=8, figsize=(24, 7))  # 3 rows, 8 columns\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.05)  # Reduce the white space between subplots\n",
    "\n",
    "    for row, ax_row in enumerate(axes):\n",
    "        if row == 0:  # Ground Truth Row\n",
    "            for i, ax in enumerate(ax_row):\n",
    "                if i < 3:\n",
    "                    # Plot frames from 0-9 from prev (first 3)\n",
    "                    frame = prev[sampled_gt_indices_prev[i]]\n",
    "                    ax.imshow(frame, cmap=cmap, norm=norm, vmin=vmin, vmax=vmax)\n",
    "                    ax.set_title(f'Input {sampled_gt_indices_prev[i]}', fontsize=10)  # Smaller font size\n",
    "                else:\n",
    "                    # Plot 5 sampled frames from 10-29 from true\n",
    "                    frame = true[sampled_gt_indices_true[i-3] - 10]  # Offset by -10 to match true frames starting from 10\n",
    "                    ax.imshow(frame, cmap=cmap, norm=norm, vmin=vmin, vmax=vmax)\n",
    "                    ax.set_title(f'Ground Truth {sampled_gt_indices_true[i-3]}', fontsize=10)  # Smaller font size\n",
    "                \n",
    "                # Remove x and y axis numbers\n",
    "                ax.set_xticks([])  # Remove x-axis numbers\n",
    "                ax.set_yticks([])  # Remove y-axis numbers\n",
    "        \n",
    "        elif row == 1:  # Prediction Row\n",
    "            for i, ax in enumerate(ax_row):\n",
    "                if i < 3:\n",
    "                    # Leave first 3 subplots empty for predictions (since pred starts at frame 10)\n",
    "                    ax.axis('off')\n",
    "                else:\n",
    "                    # Plot 5 sampled frames from pred (10-29 in true corresponds to 0-19 in pred)\n",
    "                    frame = pred[sampled_pred_indices[i-3]]\n",
    "                    ax.imshow(frame, cmap=cmap, norm=norm, vmin=vmin, vmax=vmax)\n",
    "                    ax.set_title(f'Prediction {sampled_pred_indices[i-3] + 10}', fontsize=8)  # Smaller font size\n",
    "\n",
    "                # Remove x and y axis numbers\n",
    "                ax.set_xticks([])  # Remove x-axis numbers\n",
    "                ax.set_yticks([])  # Remove y-axis numbers\n",
    "        \n",
    "        elif row == 2:  # Error Row\n",
    "            for i, ax in enumerate(ax_row):\n",
    "                if i < 3:\n",
    "                    # Leave first 3 subplots empty for errors (since no prediction exists for these frames)\n",
    "                    ax.axis('off')\n",
    "                else:\n",
    "                    # Plot absolute error for sampled frames from 10-29 in true and pred (0 to 19 in pred)\n",
    "                    gt_frame = true[sampled_gt_indices_true[i-3] - 10]  # Offset by -10 to match true frames starting from 10\n",
    "                    pred_frame = pred[sampled_pred_indices[i-3]]\n",
    "                    abs_error = np.abs(gt_frame - pred_frame)\n",
    "                    ax.imshow(abs_error, cmap=cmap, norm=norm, vmin=vmin, vmax=vmax)\n",
    "                    ax.set_title(f'Absolute Error {sampled_pred_indices[i-3] + 10}', fontsize=10)  # Smaller font size\n",
    "\n",
    "                    # Calculate MRE (Mean Relative Error)\n",
    "                    num_pixels = np.prod(gt_frame.shape)\n",
    "                    squared_error = np.sum((gt_frame - pred_frame) ** 2) / num_pixels\n",
    "                    phi_gt_max = np.max(gt_frame)\n",
    "                    phi_gt_min = np.min(gt_frame)\n",
    "                    mre = np.sqrt(squared_error) / (phi_gt_max - phi_gt_min) * 100\n",
    "\n",
    "                    # Display MRE below the subplot\n",
    "                    ax.text(0.5, -0.1, f'MRE: {mre:.4f}%', fontsize=10, color='blue', ha='center', transform=ax.transAxes)  # Smaller text size\n",
    "\n",
    "                # Remove x and y axis numbers\n",
    "                ax.set_xticks([])  # Remove x-axis numbers\n",
    "                ax.set_yticks([])  # Remove y-axis numbers\n",
    "\n",
    "    # Save the figure for each case\n",
    "    if out_path is not None:\n",
    "        output_path = os.path.join('prediction_gif', out_path + '.png')\n",
    "        plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"Figure saved as {output_path}\")\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "# Example of how to call the modified function:\n",
    "for i in range(len(inputs)):\n",
    "    example_idx = i\n",
    "\n",
    "    # Modify the output filename to include the example index\n",
    "    output_png_filename = f'example_{example_idx}'\n",
    "    show_video_gif_multiple_withError(inputs[example_idx], trues[example_idx], preds[example_idx], out_path=output_png_filename)\n",
    "\n",
    "    print(f\"Figure saved as {output_png_filename}.png in prediction_gif folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSTL_dev",
   "language": "python",
   "name": "openstl_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
